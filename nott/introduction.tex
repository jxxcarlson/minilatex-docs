beginMetadata:
{
    "id": "6dde9777-daf0-45ab-9be3-1bef5fefb13f",
    "documentNumber": 297,
    "author": "jxxcarlson",
    "title": "Introduction",
    "path": "nott/introduction.tex",
    "tags": [],
    "keyString": "introduction a=jxxcarlson nott/introduction.tex ",
    "timeCreated": 1604728291106,
    "timeModified": 1605284497942,
    "public": true,
    "collaborators": [],
    "docType": "miniLaTeX",
    "versionNumber": 1,
    "versionDate": 1607014512284
}
endMetadata
\setcounter{section}{1}

\xlink{uuid:defbbdbb-d45d-46d1-96b0-371a7048ba41}{Notes on Type Theory}

\include{435}

\begin{textmacro}
\newcommand{\xcode}[1]{\blue{#1}}
\end{textmacro}

\section{Introduction}

((\italic{WORK IN PROGRESS}))

\innertableofcontents

\subsection{The Type of Natural Numbers}

Set theory provides a language in which we can formulate and work with mathematical ideas such as the set of natural numbers $\bbN = \{ 0, 1, 2, \ldots \}$, statements such as $5 \in \bbN$, $7/2 \not\in \bbN$,  etc.  The goal of these notes is to explain an alternative language, the \term{type theory} of Per Martin-Löf (MLTT).  The purely theoretical discussion is complemented by code examples in the programming language Agda, which implements MLTT.  See \href{https://plfa.github.io/}{Wadler} for much more on Agda as well as an introduction to type theory.

As a general matter,  to define a type we must (a) give it a name, (b) describe how to construct elements of it, and (c) describe how to determine whether two elements are equal, and (d) describe how to define functions from the given type to another type. In this context, \italic{to construct} is to give a procedure or set of rules that can be carried out by human or machine that "build" elements of the given type.  

To understand these rules, we study how they apply to defining the type of natural numbers. For (a), we say this:

\begin{equation}
\label{nat:intro}
\bbN: \mathcal{U}
\end{equation} 

where $\mathcal{U}$ is some universe of types.  This is a so-called \term{formation rule}.  It simply announces that a certain symbol will be the name of a new a type. It gives no information on what the elements or \term{terms} of that type may be or what we may do with them.


\strong{A remark on universes.} Universes are arranged in a chain $\mathcal{U_0} \subset \mathcal{U_1} \subset \mathcal{U_2} \subset \cdots$ where $\mathcal{U}$ may be used as a shorthand for $\mathcal{U_\ell}$, often with $\ell = 0$.  In the programming language Agda, which implements MLTT, this hierarchy is written $\Set_0 \subset \Set_1 \subset \Set_2 \subset \cdots$ where $\Set$ is shorthand for $\Set_0$.  One must take care with this terminology because types are not sets.  More on this later. 

The need for a hierarchy of type universes goes back to Bertrand Russell and his work on avoiding paradoxes in set theory.  Consider the set

\begin{equation}
\label{russell:set}
R = \{ a\ |\space a \not\in R \}
\end{equation}

The question \italic{is $R$ and element of itself?} has no resolution.  If one assumes that $\R \in R$, one concludes $\R \not\in R$.  If one assumes $R \not\in R$, one concludes $R \in R$

For (b), construction of elements, we posit two rules for the type $\bbN$.  The first tells us how to construct a single term:

\begin{equation}
\label{construct-zero}
\zero : \bbN
\end{equation} 

The second rule says that if \code{k} is a term of $\bbN$, then so is $\suc k$, the "succesor", or next element.  We write the rule as a "fraction," where the numerator is the \term{premise} and the denominator is the \term{conclusion}.

\begin{equation}
\label{construct-succ}
\frac{k: \mathbb{N}}{\text{succ}\space k : \mathbb{N}}
\end{equation}

The first rule can be written in the same form, but with an empty premise:

\begin{equation}
\label{construct-zero-b}
\frac{}{\text{zero}\space : \mathbb{N}}
\end{equation} 

Rules with empty premises are called \term{axioms}, and are usually written in the form \eqref{construct-zero}.  One can construct arbitrarily many elements of the type of natural numbers by with applying \eqref{construct-succ} again and again to \eqref{construct-zero}.  Doing so yields an infnite sequence of terms:

\begin{align}
& \zero \\
& \suc \zero \\
& \suc \suc \zero \\
& etc.
\end{align}

If we wish, we may introduce the aliases $0, 1, 2, etc.$, etc. for these terms, so that $\suc\ 0 = 1$, $\suc 1 = 2$, etc.

The rules \eqref{nat:intro}, \eqref{construct-zero} and \eqref{construct-succ} are called \term{judgements}. Judgement \eqref{nat:intro} is a \term{formation rule}.  It announces a new type. Judgements \eqref{construct-zero} and \eqref{construct-succ} are \term{introduction rules}.  They provide \term{constructors} which tell us how to fabricate terms of the given type.  

The first of the above rules is a \term{literal constructor}: what does $\zero$ construct?  Answer: the term $\zero$ itself. The second introduction rule provides a constructor $\suc$ which we may view as a function $\suc : \bbN \to \bbN$. 

Everything that we have said so far can be implemented in Agda in three lines of code.

\begin{verbatim}
data ℕ : Set where
  zero : ℕ
  suc  : ℕ → ℕ
\end{verbatim}

Thinking back to the rules mentioned above, the Agda code announces the type (Rule a, formation), then exhibits the constructors (Rule b, introduction).    Notice the sequence: types first, then terms.  There is no such thing in MLTT as a "disembodied term," one that exists apart from a type: it is the rules of the type that provides the means to construct its terms. 

As an illustration of the general method, consider the the type of Booleans, which we define this way:

\begin{verbatim}
data Bool  : Set where
  true  : Bool
  false : Bool
\end{verbatim}

The type of Booleans is inhabited by just two terms, \blue{true} and \blue{false}.  Below we we learn how to define the usual logical operations on Booleans.

\subheading{Sets vs Types}

In set theory it makes sense to ask \italic{is $7/2$ an element of $\bbN$?}  The response is \italic{$7/2 \in \bbN$ is false.} In type theory we cannot formulate such a question because to say  $7/2 : \bbN$ is nonsensical. There is no sequence of constructions which starts with the axiom and ends with $7/2$.  In type theory, one can speak only of that which can be constructed.  As we shall see shortly, to give a proof is also to provide a construction.

\subsection{Function types}

In defining the natural numbers, we introduced the constructors $\zero$ and $\suc$.  They were used to construct terms of the type $\bbN$.  There are also constructors that manufacture new types from old.  If one is given types $A$ and $B$ in $\mathcal{U}$, then $A \to B: \mathcal{U}$ is the type of functions from $A$ to $B$.  Consequently, in the context of $\mathcal{U}$, $\to$ is a \term{constructor} of types rather than a constructor of terms.  We can formulate the construction of function types just as we formulated the behavior of $\suc$:

\begin{equation}
\frac{A, B : \text{Set}_\ell}{A \to B : \text{Set}_\ell}
\end{equation}

Construction of function types can be iterated.  Thus, given a third type $C$, one can form the type  $A \to (B \to C)$.  It is the type of functions from $A$ to functions from $B$ to $C$.  
By convention, construnction of functions types associates to the right, so we can write  $A \to B \to C$ for $A \to (B \to C)$ 

The introduction rule for the function type is stated in terms of the lambda calculus.  Suppose given types $A$ and $B$, a variable $x$ of type $A$, and an expression $e$ of type $B$.  Then $\lambda x.e$ is a function from $A$ to $B$.  In symbols, we have the introduction rule

\begin{equation}
\frac{x : A \quad e: B}{\lambda (x).e : A \to B}
\end{equation}

The meaning of a funciton $f : A \to B$ is given by the corresponding \term{elimination rule},  which tells us that there is a way of applying $f$ to terms of $A$ to produce terms of $B$:

\begin{equation}
\frac{f: A \to B\quad a : A}{f(a):B}
\end{equation}

That is, $f$ applied to $a$, a term of type $A$, is a term of type $B$.  The meaning of function application for the funciton $\lambda\thinspace x.e$ is given by the \term{computation rule}

\begin{equation}
(\lambda\thinspace x.e) a = e[x := a]
\end{equation}

where the expression $e[x := a]$ means: replace all occurrences of $x$ in $e$ by $a$.  A computation rule tells us what happens when we follow construction by elimination.

By way of example, consider the expression $\lambda\thinspace x.x$. Then $(\lambda\thinspace x.x)a = a$.  In other words, $\lambda\thinspace x.x$ is the identity function $A \to A$.  Just as simple is the function $\lambda\thinspace x.a$.  If $b: A$, then $(\lambda\thinspace x.a)b = a$.  This is the constant function $A \to A$ that has constant value $b: A$.

Let's look at a few more examples. Consider $\lambda x.\lambda y.x$, where $x: A$ and $y: A$.  If $a : A$, then $(\lambda x.\lambda y.x)\thinspace a= \lambda y.a: A \to A$.  In other words,
$\lambda x.\lambda y.y$ is a function $A \to A \to A$; when we apply it to $a : A$, the resulting value is the constant function $\lambda y.a : A \to A$.  Finally, $(\lambda x.\lambda y.y)\thinspace a\thinspace b = a$. Is a kind of projection onto the first argument.

 More generally, suppose given

$$
f : A \to B \to C.
$$

We read this as "the function type $A \to B \to C$ has a term $f$."  Then $f\ a : B \to C$ for any term $a : A$, and $(f\ a)\ b : C$ for terms $a: A$ and $b: B$.  To avoid writing unnecessary, parentheses, we take application of a function to arguments as associating to the left, so that we may write $(f\ a)\ b$  as $f\ a\ b$.

In type theory, Agda, Haskell, Elm, etc., functions are always functions of one variable.  As a consequence, functions $f$ and $g$ can always be composed as $g\circ f$, so long as the type of the codomain of $f$ is the same as the type of the domain of $g$.

\href{https://www.quora.com/In-type-theory-what-is-an-eliminator-and-what-is-its-opposite}{Conor McBride on eliminators}

As an example, define the function 

\begin{align}
& add : \bbN \to \bbN \to \bbN \\
& add\ x\ y = x + y
\end{align}

so that, for example, $add\ 1\ 2$ has value 3. Here we use the convention common to both type theory and  to functional languages such as Agda, Elm, and Haskell, writing $add\ 1\ 2$ rather than $add(1,2)$. 


Consider now the expression $add\ 1$.  It makes perfect sense as the function of type $\bbN \to \bbN$ which adds 1 to its argument. 



\subsection{Addition, etc.}

Above, in just a few lines of text, we have defined  the type of natural numbers.  But what of famiilar operations such as addition, multiplication, familiar laws such as the associative and commutative laws?  These can also be defined in type theory.  For addition, three rules are enough:

\begin{verbatim}
_+_ : N →  N →  N          (type)
0 + n = n                  (base)
succ m + n = suc (m + n)   (ind) 
\end{verbatim}

The effect tof the first line is to declare that $+$ is a binary operator of the given type: its operands are natural numbers and so is the result of applying it to natural numbers.


The second and third rules are sufficent to compute any sum.
By way of example, let us compute the sum $2 + 3$.  As above, we take $2$ as a synonym for $\suc \suc 0$, and we take $3$ as a synonym for $\suc \suc \suc 0$, etc.
Then we have equations

\begin{align}
& 2 + 3 \\
 & = suc\ (suc\ zero) + suc\ (suc\ (suc\ 0)) & (a)\\
& = suc\ (suc\ zero + suc\ (suc\ (suc\ 0))  & (b)\\
& =  suc\ suc\ (zero + suc\ (suc\ (suc\ 0)))  &(c) \\
& =  suc\ (suc\ ( suc\ (suc\ (suc\ 0)) )) & (d) \\
& = 5  
\end{align}

Each line  follows for the one preceeding from one of the  equations defining addition.  In each case  we determine the rule to use, (base) or (ind), by matching rules with the expression to be transformed.  For  line $(a)$, the rule that matches is  (ind) with $m = suc\  zero$ and $n = suc\ suc\ suc\ zero$. Therefore the transform of line $(a)$ is line $(b)$.  Line $(c)$ is obtained inthe same way.  However, On the other hand, the "inside" of line $(c)$ matches (base) with $n = suc\ suc\ suc\ zero$, and so line $(d)$ follows form line $(c)$.  This form of inference is called \term{pattern matching}.  The pattern-matching definition of addition is said to be \term{recursive} because the definition refers to itself.  



\subsection{Definitional equality}

Let us look again at a simple expression such as  \blue{suc 0 + suc 0}. It reduces to \blue{suc suc 0} via the following process:
$$
\suc 0 + \suc 0 \to \suc ( 0 + \suc 0) \to \suc \suc 0
$$

By "reduce," we mean repeatedly apply the rules. In this case, repeated application leads to a form which cannot be reduced further.  Such a form is said ot be \term{normal}.  It is a feature of type theory that normal forms exist and are unique.  An element in normal form is called \term{canonical}.  Such elements are easily recognized: they contain only constructors.


Ttwo terms that have the same canonical element are said to be "convertible" (one into the other), equal by definition," or \term{definitionally equal}.  Thus \blue{suc 0 + suc 0} and \blue{suc suc 0} are definitionally equal.  If $a$ and $b$ are definitionally equal, we write $a = b$.  

The question of whether two elements of a type are definitionally equal is \term{decidable}. It can be carried out by an algorithm which is guaranteed to terminate in finitely many steps.  As we shall see shortly, there is another kind of equality called \term{propositional equality} which is writtten as  $a \equiv_T b$, where $a, b: T$ are terms of the same type. Roughly speaking, to establish propositional equality one must give a proof in the context of type theory.  We will see how to do that shortly.  Definitional equality is a kind of trivial proof, and so terms whicih are definitionally equal are also propositionally equal.


\subsection{Propositional Equality}


In type theory one also has \term{propositional equality}.  Suppose that $a$ and $b$ are terms of the same type $A$.  Then there is a type  $a \equiv_A b$.  To say that $a$ and $b$ are propositionally equal is to say that there exists a term of type $a \equiv_A b$.    In Martin-Löf type theory, there is exactly one constructor for this type, the term $\text{refl} : a =_A a$.    The terminology stems from the reflexive law of equality. 


Since  the type $2 \equiv_\bbN 2$ is inhabited by the term \blue{refl}, The number 2 is propositinally equal to itself.  We also have propositional equality of $2 + 2$ and $4$, since the type $2 + 2 \equiv_\bbN 4$ is equal to the type $4 \equiv_\bbN 4$, which is inabited by \blue{refl}.  On the other hand, $2 + 3$ is not propositionally equal to $4$, since $2 + 3 \equiv_\bbN 4$ is the same as the type $4 \equiv_\bbN 5$, which is not inhabited.

Terms that are definitionally equal are also propositionally equal.  However, as we see in the next section, propositionally equal terms are not in general definitionally equal.

It is natural to ask whether the assertion that there is at most one inhabitant of an equality is forced up upon us.  The answer is no, a fact which leads to the subject of Homotopy Type Theory (HoTT).


